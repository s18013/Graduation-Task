{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "167b918dfc5ebee9ee63a49d89825ab4e1a5928d2b3aae65283b6b5a4bdb7333"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datatable'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8992beda87e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdatatable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datatable'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import datatable as dt\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "# import riiideducation\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_dict = {\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32', \n",
    "    'content_id': 'int16', \n",
    "    'content_type_id':'int8', \n",
    "    'task_container_id': 'int16',\n",
    "    #'user_answer': 'int8',\n",
    "    'answered_correctly': 'int8', \n",
    "    'prior_question_elapsed_time': 'float32', \n",
    "    'prior_question_had_explanation': 'bool'\n",
    "}\n",
    "target = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# **LGBM Modeling**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_lgbm=True\n",
    "clfs = list()\n",
    "params = {\n",
    "'num_leaves': 350,\n",
    "'max_bin':700,\n",
    "'min_child_weight': 0.03454472573214212,\n",
    "'feature_fraction': 0.58,\n",
    "'bagging_fraction': 0.58,\n",
    "#'min_data_in_leaf': 106,\n",
    "'objective': 'binary',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.05,\n",
    "\"boosting_type\": \"gbdt\",\n",
    "\"bagging_seed\": 11,\n",
    "\"metric\": 'auc',\n",
    "\"verbosity\": -1,\n",
    "'reg_alpha': 0.3899927210061127,\n",
    "'reg_lambda': 0.6485237330340494,\n",
    "'random_state': 47\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains=list()\n",
    "valids=list()\n",
    "num=1\n",
    "for i in range(0,num):\n",
    "  \n",
    "    #train_df=train_df.reset_index(drop=True)\n",
    "    train_df_clf=train_df.sample(n=20000*1000)\n",
    "    print('sample end')\n",
    "    #train_df.drop(train_df_clf.index, inplace=True)\n",
    "    #print('train_df drop end')\n",
    "    \n",
    "   \n",
    "    del train_df\n",
    "    \n",
    "    users=train_df_clf['user_id'].drop_duplicates()#去重\n",
    "    \n",
    "    users=users.sample(frac=0.025)\n",
    "    users_df=pd.DataFrame()\n",
    "    users_df['user_id']=users.values\n",
    "  \n",
    "  \n",
    "    valid_df_newuser = pd.merge(train_df_clf, users_df, on=['user_id'], how='inner',right_index=True)\n",
    "    del users_df\n",
    "    del users\n",
    "    gc.collect()\n",
    "    #\n",
    "    train_df_clf.drop(valid_df_newuser.index, inplace=True)\n",
    "   \n",
    "    #-----------\n",
    "    #train_df_clf=train_df_clf.sample(frac=0.2)\n",
    "    #train_df_clf.drop(valid_df_newuser.index, inplace=True)\n",
    "    train_df_clf = pd.merge(train_df_clf, questions_df, on='content_id', how='left',right_index=True)#\n",
    "    valid_df_newuser = pd.merge(valid_df_newuser, questions_df, on='content_id', how='left',right_index=True)\n",
    "\n",
    "    #  train_df_clf = pd.merge(train_df_clf, user_lecture_stats_part, on='user_id', how=\"left\",right_index=True)\n",
    "#     valid_df_newuser = pd.merge(valid_df_newuser, user_lecture_stats_part, on='user_id', how=\"left\",right_index=True)\n",
    "\n",
    "    valid_df=train_df_clf.sample(frac=0.09)\n",
    "    train_df_clf.drop(valid_df.index, inplace=True)\n",
    "   \n",
    "    valid_df = valid_df.append(valid_df_newuser)\n",
    "    del valid_df_newuser\n",
    "    gc.collect()\n",
    "    #\n",
    "\n",
    "    trains.append(train_df_clf)\n",
    "    valids.append(valid_df)\n",
    "    print('train_df length:', len(train_df_clf))\n",
    "    print('valid_df length：',len(valid_df))\n",
    "    #train_df=train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df_clf\n",
    "del valid_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,num):\n",
    "   \n",
    "    tr_data = lgb.Dataset(trains[i][features], label=trains[i][target])\n",
    "    va_data = lgb.Dataset(valids[i][features], label=valids[i][target])\n",
    "    \n",
    "#     del train_df_clf\n",
    "#     del valid_df\n",
    "#     gc.collect()\n",
    "    del trains\n",
    "    del valids\n",
    "    gc.collect()\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        tr_data,\n",
    "#         train_df[features],\n",
    "#         train_df[target],\n",
    "        num_boost_round=5000,\n",
    "        #valid_sets=[(train_df[features],train_df[target]), (valid_df[features],valid_df[target])], \n",
    "        valid_sets=[tr_data, va_data],\n",
    "        early_stopping_rounds=50,\n",
    "        feature_name=features,\n",
    "        categorical_feature=categorical_columns,\n",
    "        verbose_eval=50\n",
    "    )\n",
    "    clfs.append(model)\n",
    "    #print('auc:', roc_auc_score(valid_df[target], model.predict(valid_df[features])))\n",
    "    #model.save_model(f'model.txt')\n",
    "    lgb.plot_importance(model, importance_type='gain')\n",
    "    plt.show()\n",
    "\n",
    "    del tr_data\n",
    "    del va_data\n",
    "    gc.collect()"
   ]
  }
 ]
}